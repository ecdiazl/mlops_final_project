{
  "pipelineSpec": {
    "components": {
      "comp-data-preprocessing": {
        "executorLabel": "exec-data-preprocessing",
        "inputDefinitions": {
          "artifacts": {
            "dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "scaled_dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-deploy-sgd-model": {
        "executorLabel": "exec-deploy-sgd-model",
        "inputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "vertex_endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "vertex_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-model-training": {
        "executorLabel": "exec-model-training",
        "inputDefinitions": {
          "artifacts": {
            "scaled_dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-read-bigquery-table": {
        "executorLabel": "exec-read-bigquery-table",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-data-preprocessing": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "data_preprocessing"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.5' 'scikit-learn==1.0.2' 'kfp==1.8.22' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef data_preprocessing(\n    dataset: Input[Dataset],\n    scaled_dataset: Output[Dataset],\n):\n    \"\"\"Preprocesses tabular data for training.\"\"\"\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n\n    # lee los datos de entrada\n    df = pd.read_csv(dataset.path)\n\n    # separamos el target del resto de las variables\n    X, y = df.iloc[:,1:-1], df[['target']]\n    columns_x = X.columns\n\n    # escalamos las variables\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    X = pd.DataFrame(X, columns=columns_x)\n\n    # concatenamos las variables escaladas con el target\n    df_scaled = pd.concat([X, y], axis=1)\n\n    # guardamos el archivo como CSV\n    df_scaled.to_csv(scaled_dataset.path, index=False)\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-deploy-sgd-model": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "deploy_sgd_model"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-aiplatform==1.25.0' 'kfp==1.8.22' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef deploy_sgd_model(\n    model: Input[Model],\n    project_id: str,\n    vertex_endpoint: Output[Artifact],\n    vertex_model: Output[Model],\n):\n    \"\"\"Deploys an SGDClassifier model to Vertex AI Endpoint.\n\n    Args:\n        model: The model to deploy.\n        project_id: The project ID of the Vertex AI Endpoint.\n\n    Returns:\n        vertex_endpoint: The deployed Vertex AI Endpoint.\n        vertex_model: The deployed Vertex AI Model.\n    \"\"\"\n    from google.cloud import aiplatform\n\n    aiplatform.init(project=project_id)\n\n    deployed_model = aiplatform.Model.upload(\n        display_name=\"cardiovascular-disease-model\",\n        artifact_uri=model.uri,\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest\",\n    )\n    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n\n    vertex_endpoint.uri = endpoint.resource_name\n    vertex_model.uri = deployed_model.resource_name\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-model-training": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "model_training"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.5' 'scikit-learn==1.0.2' 'joblib==1.1.0' 'kfp==1.8.22' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef model_training(\n    scaled_dataset: Input[Dataset],\n    model: Output[Model],\n    metrics: Output[Metrics],\n):\n    \"\"\"Trains a model on tabular data.\"\"\"\n    import pandas as pd\n    import joblib\n    import os\n    from sklearn.linear_model import SGDClassifier\n    from sklearn.metrics import (accuracy_score, precision_recall_curve,\n                                 roc_auc_score)\n    from sklearn.model_selection import (RandomizedSearchCV, StratifiedKFold,\n                                         train_test_split)\n\n    # read the data\n    df = pd.read_csv(scaled_dataset.path)\n\n    # split the data into X and y\n    X, y = df.iloc[:, :-1], df[['target']]\n\n    # Assuming X and y are predefined\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n    params = {\n        \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n        \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n        \"loss\": [\"hinge\", \"log\", \"modified_huber\"],\n        \"max_iter\": [1000, 2000, 3000]\n    }\n\n    sgd_model = SGDClassifier(random_state=42)\n\n    folds = 3\n    param_comb = 10\n\n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n\n    random_search = RandomizedSearchCV(\n        sgd_model,\n        param_distributions=params,\n        n_iter=param_comb,\n        scoring=\"precision\",\n        n_jobs=4,\n        cv=skf.split(X_train, y_train),\n        verbose=4,\n        random_state=42,\n    )\n\n    random_search.fit(X_train, y_train)\n    sgd_model_best = random_search.best_estimator_\n    predictions = sgd_model_best.predict(X_test)\n    score = accuracy_score(y_test, predictions)\n    auc = roc_auc_score(y_test, predictions)\n    _ = precision_recall_curve(y_test, predictions)\n\n    metrics.log_metric(\"accuracy\", (score * 100.0))\n    metrics.log_metric(\"framework\", \"SGDClassifier\")\n    metrics.log_metric(\"dataset_size\", len(df))\n    metrics.log_metric(\"AUC\", auc)\n\n    # Export the model to a file\n    os.makedirs(model.path, exist_ok=True)\n    joblib.dump(sgd_model_best, os.path.join(model.path, \"model.joblib\"))\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-read-bigquery-table": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "read_bigquery_table"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery[pandas]==3.10.0' 'kfp==1.8.22' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef read_bigquery_table(\n    project_id: str, \n    dataset_id: str, \n    table_id: str,\n    dataset: Output[Dataset],\n):\n    \"\"\"\n    Lee datos de una tabla de BigQuery.\n\n    Args:\n    project_id: ID del proyecto en GCP.\n    dataset_id: ID del conjunto de datos en BigQuery.\n    table_id: ID de la tabla en el conjunto de datos.\n\n    Returns:\n    Una cadena que representa una parte de los datos le\u00eddos, por ejemplo.\n    \"\"\"\n    from google.cloud import bigquery\n\n    # Crea un cliente de BigQuery.\n    client = bigquery.Client(project=project_id)\n\n    # Define la consulta para seleccionar todos los datos de la tabla.\n    query = f\"SELECT * FROM `{project_id}.{dataset_id}.{table_id}` \"\n\n    # configuramos la consulta\n    job_config = bigquery.QueryJobConfig()\n    query_job = client.query(query=query, job_config=job_config)\n\n    # Convierte los resultados en un dataframe de pandas y\n    # escribe los resultados en un archivo CSV.\n    df = query_job.result().to_dataframe()\n    df.to_csv(dataset.path, index=False)\n\n"
            ],
            "image": "python:3.7"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "mlops-fp-pipeline"
    },
    "root": {
      "dag": {
        "outputs": {
          "artifacts": {
            "model-training-metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metrics",
                  "producerSubtask": "model-training"
                }
              ]
            }
          }
        },
        "tasks": {
          "data-preprocessing": {
            "cachingOptions": {},
            "componentRef": {
              "name": "comp-data-preprocessing"
            },
            "dependentTasks": [
              "read-bigquery-table"
            ],
            "inputs": {
              "artifacts": {
                "dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "dataset",
                    "producerTask": "read-bigquery-table"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "data-preprocessing"
            }
          },
          "deploy-sgd-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-deploy-sgd-model"
            },
            "dependentTasks": [
              "model-training"
            ],
            "inputs": {
              "artifacts": {
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "model",
                    "producerTask": "model-training"
                  }
                }
              },
              "parameters": {
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "mlops-final-project-412223"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "deploy-sgd-model"
            }
          },
          "model-training": {
            "cachingOptions": {},
            "componentRef": {
              "name": "comp-model-training"
            },
            "dependentTasks": [
              "data-preprocessing"
            ],
            "inputs": {
              "artifacts": {
                "scaled_dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "scaled_dataset",
                    "producerTask": "data-preprocessing"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "model-training"
            }
          },
          "read-bigquery-table": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-read-bigquery-table"
            },
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "data_mlops_fp"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "mlops-final-project-412223"
                    }
                  }
                },
                "table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "tb_mlops_fp"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "read-bigquery-table"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model-training-metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.22"
  },
  "runtimeConfig": {}
}